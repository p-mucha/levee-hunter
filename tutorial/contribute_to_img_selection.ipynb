{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing to the Image Selection\n",
    "\n",
    "We have chosen 49 large .tif files in the 1/3 arcsecond resolution, in the USA, from which we would like to select smaller images for training. \n",
    "\n",
    "- The raw, large images, have already been processed in the following way:\n",
    "\n",
    "- 1. Created Masks\n",
    "- 2. Split images and their masks into smaller images\n",
    "- 3. Removed invalid images (those that had values below -9999)\n",
    "- 4. Removed most of empty images (just background) while keeping ~20%.\n",
    "- 5. After processing, saved in the data/intermediate/ directory\n",
    "\n",
    "**Next**: The selected 49 large images are not the only ones that have been processed, all 1/3 data has been processed in this way.\n",
    "\n",
    "- For the 49 .tifs that we want, we split them into smaller lists, so that user does not process all at a time.\n",
    "- User can now take such smaller list, and tell the code to only select ot of those images that have this file ID.\n",
    "- This basically means, we only choose out of all images those, that come from the 49 larger images that we chose.\n",
    "- As long as two users do not use the same small list of the file IDs, they can work at the same time. \n",
    "- Note by file ID I mean its original name without suffix, eg: 'USGS_13_n40w095_20240228'.\n",
    "\n",
    "**Code below**: allows to go through those images and select:\n",
    "\n",
    "(keyboard input)\n",
    "\n",
    "- (a) keep image if its good\n",
    "- (w) give image a higher weighting\n",
    "- (d) remove image\n",
    "- (q) quit \n",
    "\n",
    "Note: code checks for image overlap with all the previously chosen images before presenting current image to the user, so sometimes it might say something like: image rejected due to overlap 17%, and it will go to the next image. The threshold for acceptance is currently set to 10%.\n",
    "\n",
    "**Note: dilation is only for plotting**, the actual images that go into processed are not dilated, the levees remain one pixel thick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To contribute, simply select a list of file IDs, adjust the file_ids_I_want_to_process and run the two cells below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0 = ['USGS_13_n40w095_20240228', 'USGS_13_n35w119_20240207', 'USGS_13_n39w122_20240313', 'USGS_13_n33w098_20211124', 'USGS_13_n41w075_20221115']\n",
    "list_1 = ['USGS_13_n31w095_20240229', 'USGS_13_n34w118_20190917', 'USGS_13_n40w096_20240228', 'USGS_13_n42w076_20230227', 'USGS_13_n40w087_20210617']\n",
    "list_2 = ['USGS_13_n31w096_20240229', 'USGS_13_n41w113_20241031', 'USGS_13_n38w123_20240826', 'USGS_13_n41w112_20241031', 'USGS_13_n46w123_20240124']\n",
    "list_3 = ['USGS_13_n38w122_20240207', 'USGS_13_n35w107_20231208', 'USGS_13_n34w098_20250102', 'USGS_13_n36w091_20241002', 'USGS_13_n42w074_20241010']\n",
    "list_4 = ['USGS_13_n35w118_20221019', 'USGS_13_n39w091_20240228', 'USGS_13_n42w097_20230210', 'USGS_13_n33w117_20240327', 'USGS_13_n39w095_20240408']\n",
    "list_5 = ['USGS_13_n48w123_20240327', 'USGS_13_n40w085_20230407', 'USGS_13_n34w097_20250102', 'USGS_13_n33w118_20180313', 'USGS_13_n42w089_20241107']\n",
    "list_6 = ['USGS_13_n30w096_20240229', 'USGS_13_n33w097_20211124', 'USGS_13_n40w105_20230602', 'USGS_13_n40w076_20220524', 'USGS_13_n34w117_20240327']\n",
    "list_7 = ['USGS_13_n34w112_20240402', 'USGS_13_n47w097_20241024', 'USGS_13_n42w096_20221218', 'USGS_13_n42w088_20241107', 'USGS_13_n36w078_20151125']\n",
    "list_8 = ['USGS_13_n43w089_20241107', 'USGS_13_n40w106_20230602', 'USGS_13_n36w107_20240416', 'USGS_13_n41w074_20240925', 'USGS_13_n41w076_20221115']\n",
    "list_9 = ['USGS_13_n40w075_20210624', 'USGS_13_n34w113_20241016', 'USGS_13_n29w082_20221103', 'USGS_13_n27w081_20221103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your actual list\n",
    "file_ids_I_want_to_process = list_0 + list_1 + list_2 + list_3 + list_4 + list_5 + list_6 + list_7 + list_8 + list_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucapmgb/.conda/envs/Fathom/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/home/ucapmgb/.conda/envs/Fathom/lib/python3.11/site-packages/albumentations/core/validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:16: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:19: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  A.Lambda(\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:32: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  A.Lambda(\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:47: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  A.Lambda(\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:56: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  A.Lambda(\n",
      "/share/gpu5/ucapmgb/levee-hunter/levee_hunter/augmentations.py:66: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  A.Lambda(\n"
     ]
    }
   ],
   "source": [
    "from levee_hunter.processing.helpers import specify_helper\n",
    "bounds_file = \"/share/gpu5/pmucha/fathom/levee-hunter/data/processed/1m_1024/all_bad_bounds.txt\"\n",
    "helper = specify_helper(helper_name='bad_overlap_helper', third_arg=bounds_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: not sure if output_dir in Marco's directory will work for everyone, but it can be changed to user's personal directory if necessary and then we can combine into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images to process.\n",
      "\n",
      " ---------------Starting interactive images selection.--------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from levee_hunter.processing.dataset_images_choice import interactive_images_selection\n",
    "\n",
    "# please note, the dilation_size is only for visualisation.\n",
    "# powernorm_threshold means that if the scale on image is high, the image will be plotted with powernorm scale\n",
    "# effect sort of like log scale\n",
    "interactive_images_selection(\n",
    "    intermediate_data_path=\"/share/gpu5/ucapmgb/levee-hunter/data/intermediate/13_384\", # do not change this\n",
    "    output_dir='/share/gpu5/ucapmgb/levee-hunter/data/processed/13_384',                # adjust if needed\n",
    "    dilation_size=2,         # for visualisation only, less than 5 recommended for 1/3 data\n",
    "    figsize=(12, 6),         # for visualisation only\n",
    "    cmap='viridis',          # for visualisation only\n",
    "    plot_types=[\"image\", \"image_mask_overlay\"],       # for visualisation only\n",
    "    file_ids_toprocess=file_ids_I_want_to_process,\n",
    "    powernorm_threshold=40,  # for visualisation only\n",
    "    store_bad_bounds=False,\n",
    "    store_bad_images=False,\n",
    "    helper=helper,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
